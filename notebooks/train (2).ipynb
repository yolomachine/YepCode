{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a908e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<style>.container { width:100% !important; }</style>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a35bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tokens import tokens\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8509e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(X, y, batch_size):\n",
    "    X = tf.data.Dataset.from_tensor_slices(X)\n",
    "    y = tf.data.Dataset.from_tensor_slices(y)\n",
    "    \n",
    "    return tf.data.Dataset.zip((X, y)).shuffle(len(X)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8947ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path, max_length=1000, labels=None, min_count=100):\n",
    "    X_data, y_data, index = [], [], []\n",
    "    for i in tqdm.tqdm(open(path)):\n",
    "        ind, _, tokens, tags = i.split('\\t')\n",
    "        X_data.append(tokens.split()[:max_length])\n",
    "        y_data.append(tags.split())\n",
    "        index.append(int(ind))\n",
    "        \n",
    "    index = np.array(index)\n",
    "        \n",
    "    X_data = tf.keras.preprocessing.sequence.pad_sequences(X_data, maxlen=max_length, truncating='post', padding='post', value=0)\n",
    "    \n",
    "    if labels is None:\n",
    "        labels, counts = np.unique([j for i in y_data for j in i], return_counts=True)\n",
    "        labels = labels[counts >= min_count]\n",
    "        \n",
    "    label_to_id = {label: i for i, label in enumerate(labels)}\n",
    "    \n",
    "    for i in range(len(y_data)):\n",
    "        value = [0] * len(labels)\n",
    "        for j in y_data[i]:\n",
    "            if j in label_to_id:\n",
    "                value[label_to_id[j]] = 1\n",
    "        y_data[i] = value\n",
    "\n",
    "    y_data = np.array(y_data)\n",
    "    \n",
    "    return X_data, y_data, index, labels, label_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05694e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data, index, labels, label_to_id = prepare_data('train/tokenized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26690a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.zeros(len(labels), dtype=int)\n",
    "for i in y_data:\n",
    "    counts += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb3e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(counts, labels):\n",
    "    print(f'{i}:\\t{j}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de2eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "contests = np.unique(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e455ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa9d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_contests = rng.choice(contests, replace=False, size=int(len(contests) * 0.8) + 1)\n",
    "test_contests  = np.array([i for i in contests if i not in train_contests])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c853ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = np.isin(index, train_contests)\n",
    "test_mask  = np.isin(index, test_contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(X_data[train_mask], y_data[train_mask], 64)\n",
    "test_dataset = make_dataset(X_data[test_mask], y_data[test_mask], 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dd1831",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f115fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 128\n",
    "weights = np.zeros((len(tokens) + 1, emb_size))\n",
    "\n",
    "for i, token in enumerate(tokens):\n",
    "    try:\n",
    "        weights[i + 1] = w2v_model.wv[token]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(len(tokens) + 1, emb_size, name='token_embedding', mask_zero=True)\n",
    "embedding.build((None, ))\n",
    "embedding.set_weights([weights])\n",
    "embedding.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f51515",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input((None, ), dtype=tf.int32, name='token_input')\n",
    "embedded = embedding(inputs)\n",
    "dropout = tf.keras.layers.Dropout(0.2, name='embedding_dropout')(embedded)\n",
    "\n",
    "n_layers = 4\n",
    "kernels = [3, 5, 7]\n",
    "layers = []\n",
    "\n",
    "for k in kernels:\n",
    "    x = dropout\n",
    "    n = x.shape[-1]\n",
    "    for i in range(n_layers):\n",
    "        x = tf.keras.layers.Conv1D(n, k, activation=tf.keras.activations.swish, padding='same', name=f'conv1d_{k}_{n}')(x)\n",
    "        x = tf.keras.layers.BatchNormalization(name=f'batch_norm_{k}_{n}')(x)\n",
    "        n *= 2\n",
    "        \n",
    "    x = tf.keras.layers.GlobalMaxPooling1D(name=f'max_pool_{k}')(x)\n",
    "    layers.append(x)\n",
    "\n",
    "x = tf.keras.layers.Concatenate(axis=-1, name='pool_concatenate')(layers)\n",
    "x = tf.keras.layers.Dropout(0.2, name='concatenate_dropout')(x)\n",
    "x = tf.keras.layers.Dense(units=512, activation=tf.keras.activations.swish, name=f'dense_1')(x)\n",
    "x = tf.keras.layers.Dense(units=len(labels), activation='sigmoid', name='prediction')(x)\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=x, name='multilabel_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288040ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87410938",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29225dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tfa.metrics.F1Score(len(labels))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62fd937",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join('logs', datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "    \n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(logdir, update_freq=10),\n",
    "    tf.keras.callbacks.ModelCheckpoint(os.path.join(logdir, 'weights_{epoch}'), save_freq='epoch'),\n",
    "]\n",
    "\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.ModelCheckpoint(f'weights/{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}/{{epoch}}'),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad26ec6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(train_dataset, epochs=30, validation_data=test_dataset, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9579d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, epochs=40, validation_data=test_dataset, callbacks=callbacks, initial_epoch=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70d5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, epochs=50, validation_data=test_dataset, callbacks=callbacks, initial_epoch=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df76cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy', tfa.metrics.F1Score(len(labels))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfccf4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, epochs=80, validation_data=test_dataset, callbacks=callbacks, initial_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5056209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy', tfa.metrics.F1Score(len(labels))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e984959",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, epochs=90, validation_data=test_dataset, callbacks=callbacks, initial_epoch=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487feb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c18ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d25910",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('logs/20210624-173954/weights_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f36a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_data[test_mask], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_data[train_mask], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf3d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __calc_metrics(y_true: np.ndarray, y_pred: np.ndarray, thresholds: list = None, threshold_count: int = 100):\n",
    "    total = len(y_true)\n",
    "    thresholds = thresholds or list(np.linspace(0, 1, threshold_count))\n",
    "    metrics = []\n",
    "\n",
    "    positives = y_true.sum()\n",
    "    negatives = total - positives\n",
    "    for threshold in thresholds:\n",
    "        p = y_pred > threshold\n",
    "        t = y_true.astype(bool)\n",
    "\n",
    "        tp = np.logical_and(p, t).sum()\n",
    "        tn = np.logical_and(np.logical_not(p), np.logical_not(t)).sum()\n",
    "        fp = np.logical_and(p, np.logical_not(t)).sum()\n",
    "        fn = np.logical_and(np.logical_not(p), t).sum()\n",
    "\n",
    "        tpr = tp / positives\n",
    "        tnr = tn / negatives\n",
    "        precision = tp / (tp + fp) if tp + fp else 0\n",
    "        recall = tp / (tp + fn) if tp + fn else 0\n",
    "        accuracy = (tp + tn) / (tp + fn + tn + fp)\n",
    "        f1 = 2 * precision * recall / (precision + recall) if precision or recall else 0\n",
    "\n",
    "        metrics.append({\n",
    "            'threshold': round(threshold, 3),\n",
    "            'tpr': round(tpr, 3),\n",
    "            'tnr': round(tnr, 3),\n",
    "            'precision': round(precision, 3),\n",
    "            'recall': round(recall, 3),\n",
    "            'accuracy': round(accuracy, 3),\n",
    "            'f1': round(f1, 3)\n",
    "        })\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def __calc_rocauc(metrics):\n",
    "    coords = [(i['tpr'], i['tnr']) for i in metrics]\n",
    "    auc = 0\n",
    "    for i in range(len(coords) - 1):\n",
    "        coord_i = coords[i]\n",
    "        coord_j = coords[i + 1]\n",
    "        auc += (coord_i[0] + coord_j[0]) / 2 * (coord_j[1] - coord_i[1])\n",
    "    return coords, auc\n",
    "\n",
    "def calc_metrics(y_true_np: np.ndarray, y_pred_np: np.ndarray, plot_name: str, thresholds: list = None, do_text: bool = True):\n",
    "    thresholds = thresholds or []\n",
    "\n",
    "    metrics_for_predicted = [__calc_metrics(y_true_np[:,i], y_pred_np[:,i], threshold_count=500)\n",
    "                             for i in range(len(labels))]\n",
    "    plt.title(plot_name, fontsize=20)\n",
    "    plt.xlabel('True negative ratio', fontsize=20)\n",
    "    plt.ylabel('True positive ratio', fontsize=20)\n",
    "    plt.grid(color = 'green', linestyle = '--', linewidth = 0.5)\n",
    "    plt.plot([0, 1], [1, 0], '--', color='coral')\n",
    "    l = 0\n",
    "    for metric_batch in metrics_for_predicted:\n",
    "        coords, auc = __calc_rocauc(metric_batch)\n",
    "        plt.plot([i[1] for i in coords], [i[0] for i in coords], label=labels[l])\n",
    "        l += 1\n",
    "    plt.legend()\n",
    "\n",
    "    if not thresholds:\n",
    "        for metric_batch in metrics_for_predicted:\n",
    "            last_threshold = 0\n",
    "            for metrics in metric_batch:\n",
    "                tpr = metrics['tpr']\n",
    "                tnr = metrics['tnr']\n",
    "                if tnr > tpr:\n",
    "                    thresholds.append((last_threshold + metrics['threshold']) / 2)\n",
    "                    break\n",
    "                last_threshold = metrics['threshold']\n",
    "\n",
    "    metrics_for_predicted_with_thresholds = [__calc_metrics(y_true_np[:,i], y_pred_np[:,i], thresholds=[thresholds[i]])\n",
    "                                             for i in range(len(labels))]\n",
    "\n",
    "    total_mean_metrics = defaultdict(float)\n",
    "    for metrics in metrics_for_predicted_with_thresholds:\n",
    "        total_mean_metrics['precision'] += metrics[0]['precision']\n",
    "        total_mean_metrics['recall'] += metrics[0]['recall']\n",
    "        total_mean_metrics['accuracy'] += metrics[0]['accuracy']\n",
    "        total_mean_metrics['f1'] += metrics[0]['f1']\n",
    "\n",
    "    for key in total_mean_metrics.keys():\n",
    "        total_mean_metrics[key] /= len(labels)\n",
    "\n",
    "    s_t = '\\n'.join(map(str, thresholds))\n",
    "    s_m = '\\n'.join(map(lambda x: f'{str.upper(x[0]) + x[1:]}: {round(total_mean_metrics[x], 4)}', total_mean_metrics))\n",
    "    print(f'[{plot_name}]\\nThresholds:\\n{s_t}\\n\\nMetrics:\\n{s_m}\\n')\n",
    "    if do_text:\n",
    "        plt.text(0.3, 0.04, s_m, fontsize=14)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(12.5, 10.5)\n",
    "    fig.savefig(f'{plot_name.replace(\" \", \"_\")}{\"_text\" if do_text else \"\"}.png', dpi=200)\n",
    "    return thresholds, total_mean_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a6b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_thresholds, train_metrics = calc_metrics(y_data[train_mask], y_pred_train, plot_name=f'Token Based Model ROC (train)', do_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9355f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_thresholds, train_metrics = calc_metrics(y_data[train_mask], y_pred_train, plot_name=f'Token Based Model ROC (train)', do_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39959399",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_metrics = calc_metrics(y_data[test_mask], y_pred_test, plot_name=f'Token Based Model ROC (test)', thresholds=class_thresholds, do_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218b5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_metrics = calc_metrics(y_data[test_mask], y_pred_test, plot_name=f'Token Based Model ROC (test)', thresholds=class_thresholds, do_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e328d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7359c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2f6713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2721e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9192063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d0cdd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
